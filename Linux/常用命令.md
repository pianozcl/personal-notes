```shell
#解压并制定解压到哪个目录
tar -zxvf jdk-8u212-linux-x64.tar.gz -C /home/module/   


source profile 使配置生效
```

环境变量配置

```shell
cd /etc/profile.d/
vim my_env.sh
内容
#JAVA_HOME
export JAVA_HOME=/home/module/jdk1.8.0_212
export PATH=$PATH:$JAVA_HOME/bin

#HADOOP_HOME
export HADOOP_HOME=/home/module/hadoop-3.1.3
export PATH=$PATH:$HADOOP_HOME/bin
export PATH=$PATH:$HADOOP_HOME/sbin
```

```shell
统计一个文本中每个单词出现的次数
//制定example jar。wordcount案例。输入路径。输出路径
hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-3.1.3.jar wordcount wcinput/ ./wcoutput
输出：
aa	2
bb	1
cc	1
dd	1
ee	2
ff	1
```

```shell
//跟scp的区别是，rsync只复制改动的地方
rsync -av /home/module/hadoop-3.1.3/ root@centos3:/home/module/hadoop-3.1.3/
```

```shell
~/.ssh/known_hosts			记录当前主机访问过的其他主机ip
```

#### 配置免密码

```shell
cd ~/.ssh
ssh-keygen -t rsa
ssh-copy-id centos2  //目标主机
```

```shell
分发脚本
#!/bin/bash

#判断参数个数
if [ $# -lt 1 ]
then
        echo Not Enough Arguement!
fi

for host in centos1 centos2 centos3
do
        echo =========== $host ==============

        #遍历所有文件，挨个发送
        for file in $@
        do
                #判断文件是否存在
                if [ -e $file ]
                        then
                                #获取父目录。-P找到软连接的源文件目录，dirname $file 获取当前文件的目录
                                pdir=$(cd -P $(dirname $file); pwd)


                                #获取当前文件名称
                                fname=$(basename $file)

                                #-p 不管文件是否存在都能够创建成功,不会影响已有文件夹下的文件
                                ssh $host "mkdir -p $pdir"
                                rsync -av $pdir/$fname $host:$pdir
                        else
                                echo $file does not exist!
                fi
        done
done
```

hadoop基本命令

```shell
hadoop fs -mkdir /wcinput     创建文件夹
mapred --daemon start historyserver
mapred --daemon stop historyserver

hdfs --daemon start datanode
```

```shell
#启动停止集群脚本
#!/bin/bash
if [ $# -lt 1 ]
then
        echo "No Args Input..."
        exit;
fi

case $1 in
"start")
        echo " =================== 启动 hadoop 集群 ==================="
        echo " --------------- 启动 hdfs ---------------"
        ssh centos1 "/home/module/hadoop-3.1.3/sbin/start-dfs.sh"
        echo " --------------- 启动 yarn ---------------"
        ssh centos2 "/home/module/hadoop-3.1.3/sbin/start-yarn.sh"
        echo " --------------- 启动 historyserver ---------------"
        ssh centos1 "/home/module/hadoop-3.1.3/bin/mapred --daemon start historyserver"
;;

"stop")
        echo " =================== 关闭 hadoop 集群 ==================="
        echo " --------------- 关闭 historyserver ---------------"
        ssh centos1 "/home/module/hadoop-3.1.3/bin/mapred --daemon stop historyserver"
        echo " --------------- 关闭 yarn ---------------"
        ssh centos2 "/home/module/hadoop-3.1.3/sbin/stop-yarn.sh"
        echo " --------------- 关闭 hdfs ---------------"
        ssh centos1 "/home/module/hadoop-3.1.3/sbin/stop-dfs.sh"
;;

*)
        echo "Input Args Error..."
;;
esac
```

